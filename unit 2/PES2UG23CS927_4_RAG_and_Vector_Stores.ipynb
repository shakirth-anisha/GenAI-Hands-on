{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "411ce1c2",
      "metadata": {
        "id": "411ce1c2"
      },
      "source": [
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ace94db8",
      "metadata": {
        "id": "ace94db8"
      },
      "source": [
        "# Unit 2: RAG, Vector Stores, and Indexing"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 4a: Embeddings & Vector Space\n",
        "\n",
        "## 1. Introduction: Computers Don't Read English"
      ],
      "metadata": {
        "id": "Tk1t64uQ59Oh"
      },
      "id": "Tk1t64uQ59Oh"
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install python-dotenv --upgrade --quiet langchain langchain-huggingface sentence-transformers langchain-community"
      ],
      "metadata": {
        "id": "dy57B4vb8MLX"
      },
      "id": "dy57B4vb8MLX",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "2bd7eb17",
      "metadata": {
        "id": "2bd7eb17"
      },
      "outputs": [],
      "source": [
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "import os\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "718acb1f",
      "metadata": {
        "id": "718acb1f"
      },
      "source": [
        "## 2. Viewing a Vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "6c67eb1c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6c67eb1c",
        "outputId": "cc4acd85-d923-491e-c6b6-94a142dc8586"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dimensionality: 384\n",
            "First 5 numbers: [0.03146154433488846, 0.07303042709827423, -0.028095660731196404, 0.02582768350839615, 0.03802919760346413]\n"
          ]
        }
      ],
      "source": [
        "vector = embeddings.embed_query(\"Containers\")\n",
        "\n",
        "print(f\"Dimensionality: {len(vector)}\")\n",
        "print(f\"First 5 numbers: {vector[:5]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da0fd791",
      "metadata": {
        "id": "da0fd791"
      },
      "source": [
        "## 3. The Math: Cosine Similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "58dd1396",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58dd1396",
        "outputId": "86c61c29-2d85-4be7-c321-04b18648bbcf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iron vs Rust: 0.6303\n",
            "Iron vs Balloon: 0.2926\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "def cosine_similarity(a, b):\n",
        "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
        "\n",
        "vec_iron = embeddings.embed_query(\"Iron\")\n",
        "vec_rust = embeddings.embed_query(\"Rust\")\n",
        "vec_balloon = embeddings.embed_query(\"Balloon\")\n",
        "\n",
        "print(f\"Iron vs Rust: {cosine_similarity(vec_iron, vec_rust):.4f}\")\n",
        "print(f\"Iron vs Balloon: {cosine_similarity(vec_iron, vec_balloon):.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a90b5f7",
      "metadata": {
        "id": "5a90b5f7"
      },
      "source": [
        "### Analysis\n",
        "**Iron & Rust** score higher than **Iron & Balloon**.\n",
        "This Mathematical Distance is the foundation of all Search engines and RAG systems.\n",
        "\n",
        "This is arguably the most important concept in modern AI."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6278ad2",
      "metadata": {
        "id": "f6278ad2"
      },
      "source": [
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1865ce8f",
      "metadata": {
        "id": "1865ce8f"
      },
      "source": [
        "# Unit 2 - Part 4b: Naive RAG Pipeline\n",
        "\n",
        "## 1. Introduction: The Open-Book Test\n",
        "\n",
        "RAG (Retrieval-Augmented Generation)\n",
        "1.  **Retrieval:** Find the right page in the textbook.\n",
        "2.  **Generation:** Write the answer using that page."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install python-dotenv --upgrade --quiet faiss-cpu langchain-huggingface sentence-transformers langchain-community langchain-google-genai\n"
      ],
      "metadata": {
        "id": "yPo7kz9S8a2N"
      },
      "id": "yPo7kz9S8a2N",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "4dcd7e45",
      "metadata": {
        "id": "4dcd7e45"
      },
      "outputs": [],
      "source": [
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "import getpass\n",
        "import os\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "\n",
        "if \"GOOGLE_API_KEY\" not in os.environ:\n",
        "    os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter your Google API Key: \")\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\")\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6f457ce",
      "metadata": {
        "id": "b6f457ce"
      },
      "source": [
        "## 2. The \"Knowledge Base\" (Grounding)\n",
        "RAG introduces \"non-parametric memory\" (external facts)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "234faff9",
      "metadata": {
        "id": "234faff9"
      },
      "outputs": [],
      "source": [
        "from langchain_core.documents import Document\n",
        "\n",
        "docs = [\n",
        "    Document(page_content=\"Anisha's favorite food is Donuts with extra chocolate.\"),\n",
        "    Document(page_content=\"The secret password to the lab is 'very_very_secret_give_me_fries123'.\"),\n",
        "    Document(page_content=\"LangChain is a framework for developing applications powered by language models.\"),\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c5812c6",
      "metadata": {
        "id": "2c5812c6"
      },
      "source": [
        "## 3. Indexing ( Storing the knowledge)\n",
        "\n",
        "We use **FAISS** to store the embeddings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "c1e1581d",
      "metadata": {
        "id": "c1e1581d"
      },
      "outputs": [],
      "source": [
        "from langchain_community.vectorstores import FAISS\n",
        "\n",
        "vectorstore = FAISS.from_documents(docs, embeddings)\n",
        "retriever = vectorstore.as_retriever()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d5d826cf",
      "metadata": {
        "id": "d5d826cf"
      },
      "source": [
        "## 4. The RAG Chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "67a7a5ab",
      "metadata": {
        "id": "67a7a5ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f109debb-cd70-44d7-b312-398b6731dd3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The secret password to the lab is 'very_very_secret_give_me_fries123'.\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "template = \"\"\"\n",
        "Answer based ONLY on the context below:\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "\"\"\"\n",
        "prompt = ChatPromptTemplate.from_template(template)\n",
        "\n",
        "chain = (\n",
        "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "result = chain.invoke(\"What is the secret password?\")\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b988faa1",
      "metadata": {
        "id": "b988faa1"
      },
      "source": [
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "764e4fe9",
      "metadata": {
        "id": "764e4fe9"
      },
      "source": [
        "# Unit 2 - Part 4c: Deep Dive into Indexing Algorithms\n",
        "\n",
        "## 1. Introduction: The Scale Problem\n",
        "\n",
        "**FAISS (Facebook AI Similarity Search)** was built for this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "cc999db8",
      "metadata": {
        "id": "cc999db8"
      },
      "outputs": [],
      "source": [
        "import faiss\n",
        "import numpy as np\n",
        "\n",
        "d = 128\n",
        "nb = 10000\n",
        "xb = np.random.random((nb, d)).astype('float32')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0c4b504",
      "metadata": {
        "id": "f0c4b504"
      },
      "source": [
        "## 2. Flat Index (Brute Force)\n",
        "\n",
        "**Concept:** Check every single item.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "847ac87f",
      "metadata": {
        "id": "847ac87f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56f3f986-3ec7-4aab-af6d-aea3f1113db0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Flat Index contains 10000 vectors\n"
          ]
        }
      ],
      "source": [
        "index = faiss.IndexFlatL2(d)\n",
        "index.add(xb)\n",
        "print(f\"Flat Index contains {index.ntotal} vectors\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "507e1ffc",
      "metadata": {
        "id": "507e1ffc"
      },
      "source": [
        "## 3. IVF (Inverted File Index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "402817e5",
      "metadata": {
        "id": "402817e5"
      },
      "outputs": [],
      "source": [
        "nlist = 100\n",
        "quantizer = faiss.IndexFlatL2(d)\n",
        "index_ivf = faiss.IndexIVFFlat(quantizer, d, nlist)\n",
        "\n",
        "index_ivf.train(xb)\n",
        "index_ivf.add(xb)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c0a28c5",
      "metadata": {
        "id": "4c0a28c5"
      },
      "source": [
        "## 4. HNSW (Hierarchical Navigable Small World)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "42c18025",
      "metadata": {
        "id": "42c18025"
      },
      "outputs": [],
      "source": [
        "M = 16\n",
        "index_hnsw = faiss.IndexHNSWFlat(d, M)\n",
        "index_hnsw.add(xb)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "645d63c1",
      "metadata": {
        "id": "645d63c1"
      },
      "source": [
        "## 5. PQ (Product Quantization)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "598642ac",
      "metadata": {
        "id": "598642ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "227b0821-6fce-4cda-d0c8-d8f42171560c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PQ Compression complete. RAM usage minimized.\n"
          ]
        }
      ],
      "source": [
        "m = 8\n",
        "index_pq = faiss.IndexPQ(d, m, 8)\n",
        "index_pq.train(xb)\n",
        "index_pq.add(xb)\n",
        "print(\"PQ Compression complete. RAM usage minimized.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "k = 5\n",
        "q = np.random.random((1, d)).astype('float32')\n",
        "\n",
        "# Query Flat Index\n",
        "D_flat, I_flat = index.search(q, k)\n",
        "print(f\"\\nFlat Index Query Results (Top {k}):\\nDistances: {D_flat}\\nIndices: {I_flat}\")\n",
        "\n",
        "# Query IVF Index\n",
        "index_ivf.nprobe = 10\n",
        "D_ivf, I_ivf = index_ivf.search(q, k)\n",
        "print(f\"\\nIVF Index Query Results (Top {k}):\\nDistances: {D_ivf}\\nIndices: {I_ivf}\")\n",
        "\n",
        "# Query HNSW Index\n",
        "D_hnsw, I_hnsw = index_hnsw.search(q, k)\n",
        "print(f\"\\nHNSW Index Query Results (Top {k}):\\nDistances: {D_hnsw}\\nIndices: {I_hnsw}\")\n",
        "\n",
        "# Query PQ Index\n",
        "D_pq, I_pq = index_pq.search(q, k)\n",
        "print(f\"\\nPQ Index Query Results (Top {k}):\\nDistances: {D_pq}\\nIndices: {I_pq}\")"
      ],
      "metadata": {
        "id": "qGyOzsmtvTCx",
        "outputId": "13083fae-97c0-4178-abf5-d02c6e2553c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "qGyOzsmtvTCx",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Flat Index Query Results (Top 5):\n",
            "Distances: [[14.705984 14.87966  15.574528 15.587572 15.596102]]\n",
            "Indices: [[9810 4764 8375 6623 1660]]\n",
            "\n",
            "IVF Index Query Results (Top 5):\n",
            "Distances: [[14.705984 14.87966  15.587572 15.90209  16.149097]]\n",
            "Indices: [[9810 4764 6623 2111 2833]]\n",
            "\n",
            "HNSW Index Query Results (Top 5):\n",
            "Distances: [[14.705984  14.879661  15.587573  15.596102  15.6201935]]\n",
            "Indices: [[9810 4764 6623 1660 2215]]\n",
            "\n",
            "PQ Index Query Results (Top 5):\n",
            "Distances: [[11.727423 11.803116 11.875454 11.919543 12.28454 ]]\n",
            "Indices: [[4990 4989 1660 2970 6616]]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
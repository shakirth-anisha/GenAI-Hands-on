{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYEI6a99_brn"
      },
      "source": [
        "---\n",
        "\n",
        "Name : Shakirth Anisha\n",
        "\n",
        "SRN: PES2UG23CS927\n",
        "\n",
        "---\n"
      ],
      "id": "JYEI6a99_brn"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18nNc3wI_brr"
      },
      "source": [
        "# Part 1a: LangChain Setup & Models"
      ],
      "id": "18nNc3wI_brr"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "c1293637",
      "metadata": {
        "id": "c1293637"
      },
      "outputs": [],
      "source": [
        "%pip install python-dotenv --upgrade --quiet langchain langchain-google-genai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "630e6eec",
      "metadata": {
        "id": "630e6eec"
      },
      "outputs": [],
      "source": [
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "import getpass\n",
        "import os\n",
        "\n",
        "if \"GOOGLE_API_KEY\" not in os.environ:\n",
        "    os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter your Google API Key: \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "2910b057",
      "metadata": {
        "id": "2910b057"
      },
      "outputs": [],
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "llm_focused = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0.0)\n",
        "llm_creative = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=1.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "0de67033",
      "metadata": {
        "id": "0de67033",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45c33905-cd48-4712-c578-16fad3118c4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- FOCUSED (Temp=0) ---\n",
            "Run 1: Peace is a state of tranquility and harmony, free from conflict, violence, or disturbance.\n",
            "Run 2: Peace is a state of tranquility and harmony, free from conflict, violence, or disturbance.\n"
          ]
        }
      ],
      "source": [
        "prompt = \"Define the word 'Peace' in one sentence.\"\n",
        "\n",
        "print(\"--- FOCUSED (Temp=0) ---\")\n",
        "print(f\"Run 1: {llm_focused.invoke(prompt).content}\")\n",
        "print(f\"Run 2: {llm_focused.invoke(prompt).content}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "482e96e9",
      "metadata": {
        "id": "482e96e9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "824cbfff-fae0-45b6-c2a7-9094c1ac345c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- CREATIVE (Temp=1) ---\n",
            "Run 1: Peace is a state of calm and harmony, characterized by the absence of violence, conflict, or profound disturbance, both within individuals and among groups.\n",
            "Run 2: Peace is a state of tranquility and harmony, characterized by the absence of conflict, violence, or significant disturbance.\n"
          ]
        }
      ],
      "source": [
        "print(\"--- CREATIVE (Temp=1) ---\")\n",
        "print(f\"Run 1: {llm_creative.invoke(prompt).content}\")\n",
        "print(f\"Run 2: {llm_creative.invoke(prompt).content}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c6c155e9",
      "metadata": {
        "id": "c6c155e9"
      },
      "source": [
        "## 8. Conclusion\n",
        "\n",
        "1.  **LangChain** abstracts the messy API details.\n",
        "2.  **Tokens** are the currency of AI.\n",
        "3.  **Temperature** is a control knob for randomness."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ac6f6b24",
      "metadata": {
        "id": "ac6f6b24"
      },
      "source": [
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d52b42e",
      "metadata": {
        "id": "0d52b42e"
      },
      "source": [
        "# Part 1b: Prompts & Parsers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "a5df5576",
      "metadata": {
        "id": "a5df5576"
      },
      "outputs": [],
      "source": [
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "import getpass\n",
        "import os\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "if \"GOOGLE_API_KEY\" not in os.environ:\n",
        "    os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter your Google API Key: \")\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "a76c687f",
      "metadata": {
        "id": "a76c687f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa39d32c-375b-4c8e-be1d-c2aa16e093fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Oh, my little buttercup, that's like, a totally choice question, but also a bit of a no-brainer, isn't it? The capital of France, my dear, is Paris. It's a truly bodacious city, absolutely righteous! And please, always remember to capitalize proper nouns such as 'France' and 'Paris,' lest you look like a total dweeb. Don't be a square, now, alright?\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.messages import SystemMessage, HumanMessage\n",
        "\n",
        "messages = [\n",
        "    SystemMessage(content=\"You are an old grandmother. You use 80s slang that no one understands anymore and you care a lot about grammar.\"),\n",
        "    HumanMessage(content=\"What is the capital of France?\")\n",
        "]\n",
        "\n",
        "response = llm.invoke(messages)\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "4e5856bc",
      "metadata": {
        "id": "4e5856bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5ccd4b5-2f64-4da6-97a8-8c5d0036714f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Required variables: ['input_language', 'output_language', 'text']\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "template = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are a translator. Translate {input_language} to {output_language}.\"),\n",
        "    (\"human\", \"{text}\")\n",
        "])\n",
        "\n",
        "print(f\"Required variables: {template.input_variables}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "b48f0fbc",
      "metadata": {
        "id": "b48f0fbc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5fb1c0f5-0c60-406a-a7ee-3d8fb0ebbf75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Raw Type: <class 'langchain_core.messages.ai.AIMessage'>\n",
            "Parsed Type: <class 'langchain_core.messages.base.TextAccessor'>\n",
            "Content: Hi there! How can I help you today?\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "parser = StrOutputParser()\n",
        "\n",
        "raw_msg = llm.invoke(\"Hi\")\n",
        "print(f\"Raw Type: {type(raw_msg)}\")\n",
        "\n",
        "clean_text = parser.invoke(raw_msg)\n",
        "print(f\"Parsed Type: {type(clean_text)}\")\n",
        "print(f\"Content: {clean_text}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2661ffd1",
      "metadata": {
        "id": "2661ffd1"
      },
      "source": [
        "## 6. Conclusion\n",
        "\n",
        "- **Model** (The Brain)\n",
        "- **Prompt Template** (The Input Formatter)\n",
        "- **Parser** (The Output Formatter)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9a638a9f",
      "metadata": {
        "id": "9a638a9f"
      },
      "source": [
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de149e98",
      "metadata": {
        "id": "de149e98"
      },
      "source": [
        "# Part 1c: LCEL (LangChain Expression Language)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "016ca9c2",
      "metadata": {
        "id": "016ca9c2"
      },
      "outputs": [],
      "source": [
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "import getpass\n",
        "import os\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "if \"GOOGLE_API_KEY\" not in os.environ:\n",
        "    os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter your Google API Key: \")\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\")\n",
        "template = ChatPromptTemplate.from_template(\"Tell me a fun fact about {topic}.\")\n",
        "parser = StrOutputParser()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "c652c803",
      "metadata": {
        "id": "c652c803",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82a2b177-c77d-486d-e192-b4012bdf9bbf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here's a fun one:\n",
            "\n",
            "Their iconic black and white \"tuxedo\" isn't just for show! It's actually a clever form of camouflage called **countershading**.\n",
            "\n",
            "When viewed from above, their dark backs blend in with the dark ocean depths, making it harder for airborne predators to spot them. When viewed from below, their white bellies blend in with the bright sky or reflective water surface, making them harder for underwater predators (and prey!) to see. Pretty neat, huh?\n"
          ]
        }
      ],
      "source": [
        "prompt_value = template.invoke({\"topic\": \"Penguins\"})\n",
        "response_obj = llm.invoke(prompt_value)\n",
        "final_text = parser.invoke(response_obj)\n",
        "\n",
        "print(final_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "4f5c3f41",
      "metadata": {
        "id": "4f5c3f41",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f36db780-18de-456a-f785-d04e8d35af80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "One of the most iconic and beloved features of the original Strawberry Shortcake dolls was that they were **scented!**\n",
            "\n",
            "Each doll actually smelled like the fruit or dessert they were named after, with Strawberry Shortcake herself having a distinctive, sweet strawberry scent. It was a huge part of their charm and a big reason why they were so popular, and it's a detail many people remember fondly!\n"
          ]
        }
      ],
      "source": [
        "chain = template | llm | parser\n",
        "print(chain.invoke({\"topic\": \"Strawberry Shortcake\"}))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "749e720a",
      "metadata": {
        "id": "749e720a"
      },
      "source": [
        "## Assignment\n",
        "\n",
        "Create a chain that:\n",
        "1.  Takes a movie name.\n",
        "2.  Asks for its release year.\n",
        "3.  Calculates how many years ago that was (You can try just asking the LLM to do the math).\n",
        "\n",
        "Try to do it in **one line of LCEL**."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "import getpass\n",
        "import os\n",
        "import datetime\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "if \"GOOGLE_API_KEY\" not in os.environ:\n",
        "    os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter your Google API Key: \")\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\")"
      ],
      "metadata": {
        "id": "P9PHvZf8Y7LX"
      },
      "id": "P9PHvZf8Y7LX",
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3672e61",
        "outputId": "3e40d2be-9cf7-41eb-ac22-256645243d44"
      },
      "source": [
        "current_year = datetime.date.today().year\\\n",
        "\n",
        "prompt_template = ChatPromptTemplate.from_template(\n",
        "    \"For the movie '{movie_name}', find its release year and calculate how many years have passed since its release until the current year ({current_year}).\\n\"\n",
        "    \"Provide the answer in the format: 'The movie {movie_name} was released in [YEAR] and that was [YEARS_PASSED] years ago.'\"\n",
        ")"
      ],
      "id": "c3672e61",
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current year set to: 2026\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4375de10",
        "outputId": "6a597f41-514b-4d6a-e0cf-3402aecb3cb6"
      },
      "source": [
        "chain = prompt_template | llm | parser\n",
        "print(chain.invoke({\"movie_name\": \"Zootopia 1\", \"current_year\": current_year}))"
      ],
      "id": "4375de10",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The movie Zootopia 1 was released in 2016 and that was 10 years ago.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}